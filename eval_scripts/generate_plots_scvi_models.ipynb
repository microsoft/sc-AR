{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing CSV files\n",
    "# csv_dir = \"/Users/zeinab/Documents/MSR_internship/project/MSR_internship_new_git/sc-uncertainty/result/test/ajay/zeinab-evals-ajay-blood-3-7-25/\"\n",
    "csv_dir = '/Users/zeinab/Documents/MSR_internship/project/MSR_internship_new_git/sc-uncertainty/result/test/ajay/zeinab-classification-evals-20250409-manuscript-version/'\n",
    "\n",
    "# Define expected columns\n",
    "columns = ['accuracy', 'precision', 'recall', 'micro_f1', 'macro_f1', 'seed', 'dataset', 'ARtype', 'latent_dim', 'Atlas_cell_count']\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Loop over all CSV files in the directory\n",
    "for file in os.listdir(csv_dir):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(csv_dir, file)\n",
    "        df_temp = pd.read_csv(file_path, usecols=columns)  # Load only relevant columns\n",
    "        df_list.append(df_temp)  # Store DataFrame in the list\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "df = pd.concat(df_list, ignore_index=True) if df_list else pd.DataFrame(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove repeted rows\n",
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df[df['ARtype'] == 'AR'].shape[0] == df[df['ARtype'] == 'Naive'].shape[0]\n",
    "# assert if the number of rows for each seed is the same\n",
    "assert df[df['seed'] == '42'].shape[0] \\\n",
    "    == df[df['seed'] == '43'].shape[0] \\\n",
    "    == df[df['seed'] == '44'].shape[0] \\\n",
    "    == df[df['seed'] == '45'].shape[0] \\\n",
    "    == df[df['seed'] == '46'].shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Accuracy', 'Precision', 'Recall', 'Micro F1 Score', 'Macro F1 Score', 'deed', 'dataset', 'ARtype', 'latent_dim', 'Atlas_cell_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define metrics and target columns\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'Micro F1 Score', 'Macro F1 Score']\n",
    "columns = ['dataset', 'metric', 'value', 'ARtype', 'Atlas_cell_count']\n",
    "plot_df_list = []\n",
    "\n",
    "# Loop through each row in df\n",
    "for index, row in df.iterrows():\n",
    "    for metric in metrics:\n",
    "        tmp_df = pd.DataFrame([[row['dataset'], metric, row[metric], row['ARtype'], row['Atlas_cell_count']]], \n",
    "                              columns=columns)\n",
    "        plot_df_list.append(tmp_df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "plot_df = pd.concat(plot_df_list, ignore_index=True) if plot_df_list else pd.DataFrame(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = plot_df.sort_values(by='Atlas_cell_count')\n",
    "plot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change ARtype to AR and Naive\n",
    "plot_df['ARtype'] = plot_df['ARtype'].replace({'T': 'AR', 'F': 'Standard'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a piece of code that for each dataset, metric and Atlas_cell_count, it calculated the p-value between AR and Naive using t-test\n",
    "from scipy import stats\n",
    "results = []\n",
    "for dataset in plot_df['dataset'].unique():\n",
    "    for metric in plot_df['metric'].unique():\n",
    "        for atlas_cell_count in plot_df['Atlas_cell_count'].unique():\n",
    "            ar_values = plot_df[(plot_df['dataset'] == dataset) & \n",
    "                                (plot_df['metric'] == metric) & \n",
    "                                (plot_df['Atlas_cell_count'] == atlas_cell_count) & \n",
    "                                (plot_df['ARtype'] == 'AR')]['value']\n",
    "            naive_values = plot_df[(plot_df['dataset'] == dataset) & \n",
    "                                   (plot_df['metric'] == metric) & \n",
    "                                   (plot_df['Atlas_cell_count'] == atlas_cell_count) & \n",
    "                                   (plot_df['ARtype'] == 'Standard')]['value']\n",
    "            if len(ar_values) > 1 and len(naive_values) > 1:\n",
    "                t_stat, p_value = stats.ttest_ind(ar_values, naive_values)\n",
    "                results.append([dataset, metric, atlas_cell_count, p_value])\n",
    "            else:\n",
    "                results.append([dataset, metric, atlas_cell_count, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "pval_df = pd.DataFrame(results, columns=['dataset', 'metric', 'Atlas_cell_count', 'p_value'])\n",
    "\n",
    "# print the pval_df in the form of a latex table in scientific notation with 2 decimal points, separately for each dataset, with rows as metrics and columns as Atlas_cell_count, with dataseet in caption, colored by their p-value (green for p<0.05, yellow for p>=0.05)\n",
    "for dataset in pval_df['dataset'].unique():\n",
    "    subset = pval_df[pval_df['dataset'] == dataset]\n",
    "    pivot_table = subset.pivot(index='metric', columns='Atlas_cell_count', values='p_value')\n",
    "    def color_pval(val):\n",
    "        if pd.isna(val):\n",
    "            return ''\n",
    "        elif val < 0.05:\n",
    "            return 'background-color: green; color: white;'\n",
    "        else:\n",
    "            return 'background-color: yellow; color: black;'\n",
    "    styled_table = pivot_table.style.applymap(color_pval).format(precision=2, formatter=\"{:.2e}\")\n",
    "    latex_table = styled_table.to_latex(caption=f'P-values for {dataset}', label=f'tab:pvalues_{dataset}')\n",
    "    print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results to a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['dataset', 'metric', 'Atlas_cell_count', 'p_value']\n",
    "\n",
    "# plot results_df as a heatmap using seaborn for each dataset separately, with metric on the y-axis, Atlas_cell_count on the x-axis, and p-value < 0.05 light green and >= 0.05 light red, with annotated p-values in scientific notation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for dataset in results_df['dataset'].unique():\n",
    "    pivot_df = results_df[results_df['dataset'] == dataset].pivot(index='metric', columns='Atlas_cell_count', values='p_value')\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.heatmap(pivot_df, annot=True, fmt=\".1e\", cmap=sns.color_palette([\"green\", \"red\"]), center=0.05, cbar_kws={'label': 'p-value'})\n",
    "    plt.title(f'P-values for {dataset}')\n",
    "    plt.ylabel('Metric')\n",
    "    plt.xlabel('Atlas Cell Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# plot a group barplot for each dataset with metric in x-axis and value in y-axis, hue=AR_Type\n",
    "palette = {'Standard':\"darkgray\",\n",
    "           'AR':\"brown\"}\n",
    "for dataset in plot_df['dataset'].unique():\n",
    "    \n",
    "    # loop through each metric\n",
    "    for i, metric in enumerate(metrics):\n",
    "        # create a new plot\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(6, 5))\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        g = sns.lineplot(data=plot_df[(plot_df['dataset'] == dataset) & (plot_df['metric'] == metric)], \n",
    "                         x=\"Atlas_cell_count\", y=\"value\", hue=\"ARtype\", palette=palette,\n",
    "                         hue_order=['Standard', 'AR'])\n",
    "        # set x and y labels\n",
    "        g.set_xlabel('')\n",
    "        g.set_ylabel(metric, fontsize=15)\n",
    "        # set the title of the plot\n",
    "        g.set_title(dataset.capitalize(), fontsize=18)\n",
    "        # set the font size of the x and y ticks\n",
    "        g.tick_params(axis='both', which='major', labelsize=15)\n",
    "        g.tick_params(axis='both', which='minor', labelsize=15)\n",
    "        g.legend(loc='upper left', fontsize=15)\n",
    "        g.set(ylim=(0, 1))\n",
    "        g.set_xscale(\"log\", base=10)\n",
    "        # save the plot with high resolution\n",
    "        plt.savefig(f'/Users/zeinab/Documents/MSR_internship/project/MSR_internship_new_git/sc-uncertainty/result/test/ajay/scvi_plots_manuscript/{dataset}_{metric}.png', dpi=600,\n",
    "                    bbox_inches='tight')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate plot for reconstruction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=['dataset', 'metric', 'value', 'ARtype', 'Atlas_cell_count', 'seed'])\n",
    "dir ='/Users/zeinab/Documents/MSR_internship/project/MSR_internship_new_git/sc-uncertainty/result/test/ajay/zeinab-reconstruction-evals-20250409-manuscript-version/'\n",
    "# loop over all files inside dir and read the pickle files\n",
    "for file in os.listdir(dir):\n",
    "    if file.endswith(\".pkl\") and 'Reconstruction_seed_' in file:\n",
    "        # print(file)\n",
    "        \n",
    "        # extract the dataset name, ARtype, seed and Atlas_cell_count from the file name\n",
    "        ARtype = file.split('_')[4]\n",
    "        seed = file.split('_')[2]\n",
    "        Atlas_cell_count = file.split('_')[11]\n",
    "        print('ARtype:', ARtype)\n",
    "        print('seed:', seed)\n",
    "        print('Atlas_cell_count:', Atlas_cell_count)\n",
    "    \n",
    "        # Open the pickle file in read-binary mode\n",
    "        with open(dir+file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            print(list(data.keys()))\n",
    "            dict_keys = list(data.keys())\n",
    "            for key in dict_keys:\n",
    "                test_df = data[key]\n",
    "                print(test_df.columns)\n",
    "                mean_r2 = test_df['r2'].mean()\n",
    "                mean_corr = test_df['correlation'].mean()\n",
    "                df.loc[len(df)] = [key, 'correlation', mean_corr, ARtype, Atlas_cell_count, seed]\n",
    "                df.loc[len(df)] = [key, 'r2', mean_r2, ARtype, Atlas_cell_count, seed]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include only rows with seed in [42, 43, 44, 45, 46]\n",
    "df = df[df['seed'].isin(['42', '43', '44', '45', '46'])]\n",
    "print(df[df['ARtype'] == 'T'].shape[0])\n",
    "print(df[df['ARtype'] == 'F'].shape[0])\n",
    "\n",
    "print('df[df[seed] == 42].shape[0]:', df[df['seed'] == '42'].shape[0])\n",
    "print('df[df[seed] == 43].shape[0]:', df[df['seed'] == '43'].shape[0])\n",
    "print('df[df[seed] == 44].shape[0]:', df[df['seed'] == '44'].shape[0])\n",
    "print('df[df[seed] == 45].shape[0]:', df[df['seed'] == '45'].shape[0])\n",
    "print('df[df[seed] == 46].shape[0]:', df[df['seed'] == '46'].shape[0])\n",
    "\n",
    "# print the number of rows for each Atlas_cell_count\n",
    "print('Atlas_cell_count:', df['Atlas_cell_count'].unique())\n",
    "# print the number of rows for each Atlas_cell_count=0,1,10,100,1000,10000,50000\n",
    "print('Atlas_cell_count=0:', df[df['Atlas_cell_count'] == '0'].shape[0])\n",
    "print('Atlas_cell_count=1:', df[df['Atlas_cell_count'] == '1'].shape[0])\n",
    "print('Atlas_cell_count=10:', df[df['Atlas_cell_count'] == '10'].shape[0])\n",
    "print('Atlas_cell_count=100:', df[df['Atlas_cell_count'] == '100'].shape[0])\n",
    "print('Atlas_cell_count=1000:', df[df['Atlas_cell_count'] == '1000'].shape[0])\n",
    "print('Atlas_cell_count=10000:', df[df['Atlas_cell_count'] == '10000'].shape[0])\n",
    "print('Atlas_cell_count=50000:', df[df['Atlas_cell_count'] == '50000'].shape[0])\n",
    "\n",
    "\n",
    "assert df[df['ARtype'] == 'T'].shape[0] == df[df['ARtype'] == 'F'].shape[0]\n",
    "# assert if the number of rows for each seed is the same\n",
    "assert df[df['seed'] == '42'].shape[0] \\\n",
    "    == df[df['seed'] == '43'].shape[0] \\\n",
    "    == df[df['seed'] == '44'].shape[0] \\\n",
    "    == df[df['seed'] == '45'].shape[0] \\\n",
    "    == df[df['seed'] == '46'].shape[0] \n",
    "    \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'heart' in df.dataset.lower, change it to 'Heart', if 'kidney' in df.dataset.lower, change it to 'Kidney'\n",
    "df['dataset'] = df['dataset'].apply(lambda x: 'Heart' if 'heart' in x.lower() else x)\n",
    "df['dataset'] = df['dataset'].apply(lambda x: 'Kidney' if 'kidney' in x.lower() else x)\n",
    "df['dataset'] = df['dataset'].apply(lambda x: 'Neurons' if x=='Neurons_reconstruction' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace ARtype with Standard\n",
    "df['ARtype'] = df['ARtype'].apply(lambda x: 'Standard' if x == 'F' else 'AR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a piece of code that for each dataset, metric and Atlas_cell_count, it calculated the p-value between AR and Naive using t-test\n",
    "from scipy import stats\n",
    "results = []\n",
    "\n",
    "for dataset in df['dataset'].unique():\n",
    "    for metric in df['metric'].unique():\n",
    "        for atlas_cell_count in df['Atlas_cell_count'].unique():\n",
    "            ar_values = df[(df['dataset'] == dataset) & \n",
    "                                (df['metric'] == metric) & \n",
    "                                (df['Atlas_cell_count'] == atlas_cell_count) & \n",
    "                                (df['ARtype'] == 'AR')]['value']\n",
    "            naive_values = df[(df['dataset'] == dataset) & \n",
    "                                   (df['metric'] == metric) & \n",
    "                                   (df['Atlas_cell_count'] == atlas_cell_count) & \n",
    "                                   (df['ARtype'] == 'Standard')]['value']\n",
    "            if len(ar_values) > 1 and len(naive_values) > 1:\n",
    "                t_stat, p_value = stats.ttest_ind(ar_values, naive_values)\n",
    "                results.append([dataset, metric, atlas_cell_count, p_value])\n",
    "            else:\n",
    "                results.append([dataset, metric, atlas_cell_count, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert results to a dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['dataset', 'metric', 'Atlas_cell_count', 'p_value']\n",
    "print('shape of results_df:', results_df.shape)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the latex table of results_df, with dataset in caption, colored by their p-value (green for p<0.05, yellow for p>=0.05)\n",
    "for dataset in results_df['dataset'].unique():\n",
    "    subset = results_df[results_df['dataset'] == dataset]\n",
    "    pivot_table = subset.pivot(index='metric', columns='Atlas_cell_count', values='p_value')\n",
    "    def color_pval(val):\n",
    "        if pd.isna(val):\n",
    "            return ''\n",
    "        elif val < 0.05:\n",
    "            return 'background-color: green; color: white;'\n",
    "        else:\n",
    "            return 'background-color: yellow; color: black;'\n",
    "    styled_table = pivot_table.style.applymap(color_pval).format(precision=2, formatter=\"{:.2e}\")\n",
    "    latex_table = styled_table.to_latex(caption=f'P-values for {dataset}', label=f'tab:pvalues_{dataset}')\n",
    "    print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot heatmap of p-values for each dataset, where x axis is Atlas_cell_count, y axis is metric, and color is green if p-value < 0.05 else red\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "results_df = results_df[results_df['metric'].isin(['correlation'])]\n",
    "for dataset in results_df['dataset'].unique():\n",
    "    pivot_df = results_df[results_df['dataset'] == dataset].pivot(index='metric', columns='Atlas_cell_count', values='p_value')\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    sns.heatmap(pivot_df, annot=True, fmt=\".1e\", cmap=sns.color_palette([\"green\", \"red\"]), center=0.05, cbar_kws={'label': 'p-value'})\n",
    "    plt.title(f'P-values Heatmap for {dataset}')\n",
    "    plt.xlabel('Atlas Cell Count')\n",
    "    plt.ylabel('Metric')\n",
    "    plt.axhline(y=-0.5, color='black', linewidth=2)  # Horizontal line at the top\n",
    "    plt.axvline(x=-0.5, color='black', linewidth=2)  # Vertical line at the left\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot group barplot with Atlas_cell_count in x-axis, value in y-axis, hue=ARtype\n",
    "# convert Atlas_cell_count to log scale\n",
    "\n",
    "# convert the Atlas_cell_count label into int format\n",
    "df['Atlas_cell_count'] = df['Atlas_cell_count'].astype(int)\n",
    "# sort based on Atlas_cell_count\n",
    "df = df.sort_values(by='Atlas_cell_count')\n",
    "\n",
    "# plot a group barplot for each dataset with metric in x-axis and value in y-axis, hue=AR_Type\n",
    "palette = {'Standard':\"darkgray\",\n",
    "           'AR':\"brown\"}\n",
    "\n",
    "for dataset in df['dataset'].unique():\n",
    "    # loop through each metric\n",
    "    for i, metric in enumerate(['correlation', 'r2']):\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(6, 5))\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        g = sns.lineplot(data=df[(df['dataset'] == dataset) & (df['metric'] == metric)], \n",
    "                         x=\"Atlas_cell_count\", y=\"value\", hue=\"ARtype\", palette=palette,\n",
    "                         hue_order=['Standard', 'AR'])\n",
    "        # set x and y labels\n",
    "        g.set_xticklabels(g.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "        g.set_xlabel('')\n",
    "        g.set_ylabel(metric.capitalize(), fontsize=15)\n",
    "        g.set_title(dataset.capitalize(), fontsize=18)\n",
    "        g.tick_params(axis='both', which='major', labelsize=15)\n",
    "        g.tick_params(axis='both', which='minor', labelsize=15)\n",
    "        g.set_xscale(\"log\", base=10)\n",
    "        g.legend(loc='upper left', fontsize=15)\n",
    "        g.set(ylim=(0,1))\n",
    "        \n",
    "        # save the plot with high resolution\n",
    "        plt.savefig(f'/Users/zeinab/Documents/MSR_internship/project/MSR_internship_new_git/sc-uncertainty/result/test/ajay/scvi_plots_manuscript/{dataset}_{metric}.png', dpi=600,\n",
    "                    bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeinab-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
